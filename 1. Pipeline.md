# Machine Learning Workflows/Pipelines/Lifecycles
There are 2 types of ML workflows
- Manual
- Automated: more dev time for new models, simpler & less error-prone update process for existing models, less time for reproducibility of existing models, standardization

## Why Automated ML Workflows?
1. Ability to focus on new models, not maintaining existing models
    - Maintaining existing models means running pre-processing scripts, deployment scripts, tuning of models etc
    - Job satisfaction since they will work work on new models
2. Prevention of bugs
    - Model is tied to pre-processing steps (New model for new pre-processing steps): In manual workflow, if we change pre-processing steps after the model was trained without retraining the model, then there is mismatch in pre-processing steps during training and inference time. Model won't complain about it but it is incorrect/buggy. 
    - Model is tied to versioned data (New model for new data)
3. Useful paper trail
    - Experiment tracking: records hyperparameters, dataset, metrics
    - Model release management: which model was selected and deployed
    - Assist if questions are asked around Data protection Laws (Eg: Europe has General Data Protection Regulation (GDPR))
4. Standardization
    - Easy onboarding/transfer   
    
## When to use Automated ML Workflows?
1. When model has user-base: continuous update of the model is necessary
2. Large projects

## Steps in ML Workflows
1. Data Versioning
    - Version the data which will help to tie it to the versioned trained model
2. Data Ingestion
    - Convert data into a format such that it can be consumed by next steps
    - No feature enginerring
3. Data Validation
    - Checks if the statistics of the new data are as expected (Eg: range, no. of categories, distribution of categories, etc)
    - Compares diffeerent datasets (training vs validation comparision)
    - Stops & alerts the data scientists for any anomalies (Eg: alerts if 70/30 class splits are found for binary classfication)
4. Data Preprocessing
    - Labels into numbers
    - Text into word vectors
    - Graph models
5. Model Training & Tuning
    - Core of pipeline
    - Parallely/Sequentially spin up large no. of models & play with hyperparameters and select the best model
6. Model Analysis
    - Loss determines optimal set of parameters and gives final model
    - Other metric for analysis (precision, recall, AUC, etc) to verify model predictions are fair
7. Model Versioning
    - Keeps track of model (also dataset, set of hyperparameters) to be deployed
8. Model Deployment
    - Model servers allows deploying models without writing web app code
    - Model servers provide REST or RPC interfaces
    - Model servers can host multiple versions simulataneously
    - Model servers can update the model without redeploying the web app (decouple ML & Dev team)
9. Model Feedback
    - look for the performance of the model

**Note**: Data Privacy (How can we use data so that privacy is maintained?) can also be included in the pipeline. Differential Privacy (model predictions do not expose user data), Federated Learning (raw data does not leave user device), Encrypted Learning (raw data is encrypted)

**Assumption**: Model is already designed
